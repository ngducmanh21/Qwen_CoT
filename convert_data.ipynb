{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9376044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted! Output: /home/vlai-gpt-oss/LLaMA-OSS/grpo_high.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#input_file = \"/home/vlai-gpt-oss/LLaMA-OSS/LLaMA-Factory/data/gsm8k_origin_train_alpaca.jsonl\"\n",
    "input_file = \"LLaMA-Factory/data/final/grpo_high.jsonl\"\n",
    "output_file = \"/home/vlai-gpt-oss/LLaMA-OSS/grpo_high.jsonl\"\n",
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract answer from response.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'\\\\boxed\\{([^}]+)\\}', text)\n",
    "    if match:\n",
    "        return f\"\\\\boxed{{{match.group(1)}}}\"\n",
    "    return \"\"\n",
    "\n",
    "with open(input_file, 'r') as fin, open(output_file, 'w') as fout:\n",
    "    for line in fin:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract label from response\n",
    "        label = extract_answer(data.get('label', ''))\n",
    "        \n",
    "        # Convert to GRPO format\n",
    "        grpo_data = {\n",
    "            \"query\": data.get('prompt', ''),\n",
    "            #\"response\": data.get('response', ''),  # Optional reference\n",
    "            \"label\": label  # Ground truth for reward\n",
    "        }\n",
    "        \n",
    "        fout.write(json.dumps(grpo_data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Converted! Output: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a155839",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{\"prompt\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.\\nDo NOT include explanations or reasoning in the final answer - only the numeric value in \\\\boxed{}.\", \"label\": \"\\\\boxed{72}\", \"dataset\": \"gsm8k\"}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6028f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted! Output: /home/vlai-gpt-oss/LLaMA-OSS/compmath_grpo.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"/home/vlai-gpt-oss/LLaMA-OSS/LLaMA-Factory/data/competition_math_origin_train_alpaca.jsonl\"\n",
    "output_file = \"/home/vlai-gpt-oss/LLaMA-OSS/compmath_grpo.jsonl\"\n",
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract answer from response.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'\\\\boxed\\{([^}]+)\\}', text)\n",
    "    if match:\n",
    "        return f\"\\\\boxed{{{match.group(1)}}}\"\n",
    "    return \"\"\n",
    "\n",
    "with open(input_file, 'r') as fin, open(output_file, 'w') as fout:\n",
    "    for line in fin:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract label from response\n",
    "        label = extract_answer(data.get('response', ''))\n",
    "        \n",
    "        # Convert to GRPO format\n",
    "        grpo_data = {\n",
    "            \"query\": data.get('prompt', ''),\n",
    "            \"response\": data.get('response', ''),  # Optional reference\n",
    "            \"label\": label  # Ground truth for reward\n",
    "        }\n",
    "        \n",
    "        fout.write(json.dumps(grpo_data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Converted! Output: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf3856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged into merged_grpo_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "files_to_merge = ['compmath_grpo.jsonl', 'gsm8k_grpo.jsonl']\n",
    "output_file = 'merged_grpo_data.jsonl'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for fname in files_to_merge:\n",
    "        with open(fname, 'r', encoding='utf-8') as infile:\n",
    "            for line in infile:\n",
    "                if line.strip():  # Avoid adding empty lines\n",
    "                    outfile.write(line.strip() + '\\n')\n",
    "\n",
    "print(f\"Successfully merged into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4967e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted: '72'\n",
      "  Extracted: '72'\n",
      "  Extracted: '72'\n",
      "  Extracted: '10'\n",
      "  Extracted: '10'\n",
      "\n",
      "‚úÖ Conversion complete!\n",
      "  Total: 26106\n",
      "  Extracted: 26094 (100.0%)\n",
      "  No answer: 12\n",
      "\n",
      "üìä By dataset:\n",
      "  gsm8k: 9132/9132 (100.0%)\n",
      "  logiqa: 5298/5298 (100.0%)\n",
      "  compmath: 11664/11676 (99.9%)\n",
      "\n",
      "================================================================================\n",
      "Sample outputs:\n",
      "================================================================================\n",
      "1. \\boxed{72}\n",
      "2. \\boxed{72}\n",
      "3. \\boxed{72}\n",
      "4. \\boxed{10}\n",
      "5. \\boxed{10}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_answer_from_response(response, dataset):\n",
    "    \"\"\"Extract answer from \\boxed{} - STOP at first closing brace\"\"\"\n",
    "    if not response:\n",
    "        return None\n",
    "    \n",
    "    # For LogiQA: Look for A, B, C, D\n",
    "    if dataset.lower() == 'logiqa':\n",
    "        think_match = re.search(r'<think>(.*?)</think>', response, re.DOTALL)\n",
    "        if think_match:\n",
    "            thinking = think_match.group(1)\n",
    "            answer_match = re.search(r'(?:answer|option|choice)\\s*(?:is|:|=)?\\s*([A-D])\\b', thinking, re.IGNORECASE)\n",
    "            if answer_match:\n",
    "                return answer_match.group(1).upper()\n",
    "            \n",
    "            letters = re.findall(r'\\b([A-D])\\b', thinking)\n",
    "            if letters:\n",
    "                return letters[-1].upper()\n",
    "    \n",
    "    # For math datasets: Look for #### format\n",
    "    answer_match = re.search(r'####\\s*(.+?)(?:\\n|</think>|$)', response)\n",
    "    if answer_match:\n",
    "        return answer_match.group(1).strip()\n",
    "    \n",
    "    # Look for \\boxed{} - extract content UP TO FIRST MATCHING CLOSING BRACE\n",
    "    boxed_match = re.search(r'\\\\boxed\\{', response)\n",
    "    if boxed_match:\n",
    "        start = boxed_match.end()\n",
    "        text = response[start:]\n",
    "        \n",
    "        # Count braces to find matching closing brace\n",
    "        brace_count = 1\n",
    "        end_pos = 0\n",
    "        \n",
    "        for i, char in enumerate(text):\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    end_pos = i\n",
    "                    break\n",
    "        \n",
    "        if end_pos > 0:\n",
    "            return text[:end_pos].strip()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def convert_to_grpo_format(input_file, output_file):\n",
    "    \"\"\"Convert to GRPO format with proper \\boxed{} extraction\"\"\"\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f_in, open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        stats = {\n",
    "            'total': 0,\n",
    "            'answer_extracted': 0,\n",
    "            'no_answer': 0,\n",
    "            'by_dataset': {}\n",
    "        }\n",
    "        \n",
    "        for line in f_in:\n",
    "            item = json.loads(line)\n",
    "            stats['total'] += 1\n",
    "            \n",
    "            prompt = item.get('prompt', '')\n",
    "            instruction = item.get('instruction', 'Respond concisely with minimal reasoning.')\n",
    "            response = item.get('response', '')\n",
    "            mode = item.get('mode', 'low')\n",
    "            dataset = item.get('dataset', 'unknown')\n",
    "            \n",
    "            if dataset not in stats['by_dataset']:\n",
    "                stats['by_dataset'][dataset] = {'total': 0, 'success': 0}\n",
    "            stats['by_dataset'][dataset]['total'] += 1\n",
    "            \n",
    "            # Build query\n",
    "            format_instruction = \"provide your reasoning in <think> tags, then put your final answer in \\\\boxed{}\"\n",
    "            query = f\"{instruction}\\n\\n{format_instruction}\\n\\n{prompt}\"\n",
    "            \n",
    "            # Extract answer - STOPS at matching closing brace\n",
    "            extracted_answer = extract_answer_from_response(response, dataset)\n",
    "            \n",
    "            if extracted_answer:\n",
    "                stats['answer_extracted'] += 1\n",
    "                stats['by_dataset'][dataset]['success'] += 1\n",
    "                \n",
    "                # Print first few to verify\n",
    "                if stats['answer_extracted'] <= 5:\n",
    "                    print(f\"  Extracted: '{extracted_answer}'\")\n",
    "                \n",
    "                ground_truth = f\"\\\\boxed{{{extracted_answer}}}\"\n",
    "            else:\n",
    "                stats['no_answer'] += 1\n",
    "                ground_truth = \"\\\\boxed{unknown}\"\n",
    "            \n",
    "            grpo_item = {\n",
    "                'query': query,\n",
    "                'mode': mode,\n",
    "                'answer': ground_truth\n",
    "            }\n",
    "            \n",
    "            f_out.write(json.dumps(grpo_item, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        print(f\"\\n‚úÖ Conversion complete!\")\n",
    "        print(f\"  Total: {stats['total']}\")\n",
    "        print(f\"  Extracted: {stats['answer_extracted']} ({100*stats['answer_extracted']/stats['total']:.1f}%)\")\n",
    "        print(f\"  No answer: {stats['no_answer']}\")\n",
    "        \n",
    "        print(f\"\\nüìä By dataset:\")\n",
    "        for dataset, counts in stats['by_dataset'].items():\n",
    "            rate = 100*counts['success']/counts['total'] if counts['total'] > 0 else 0\n",
    "            print(f\"  {dataset}: {counts['success']}/{counts['total']} ({rate:.1f}%)\")\n",
    "\n",
    "# Convert\n",
    "convert_to_grpo_format(\n",
    "    '/workspace/LLaMA-OSS/LLaMA-Factory/data/combined_grpo_train.jsonl',\n",
    "    '/workspace/LLaMA-OSS/train_grpo.jsonl'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample outputs:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open('/workspace/LLaMA-OSS/train_grpo.jsonl', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        print(f\"{i+1}. {data['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f108728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing: /workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_high.jsonl\n",
      "================================================================================\n",
      "Total examples: 5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HIGH:\n",
      "  Count: 5641\n",
      "  Mean: 1514.27 tokens\n",
      "  Std: 452.97 tokens\n",
      "  Min: 424 tokens\n",
      "  Max: 2880 tokens\n",
      "  Median: 1470 tokens\n",
      "\n",
      "================================================================================\n",
      "Analyzing: /workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_low.jsonl\n",
      "================================================================================\n",
      "Total examples: 10388\n",
      "\n",
      "LOW:\n",
      "  Count: 10388\n",
      "  Mean: 104.75 tokens\n",
      "  Std: 53.86 tokens\n",
      "  Min: 24 tokens\n",
      "  Max: 337 tokens\n",
      "  Median: 94 tokens\n",
      "\n",
      "================================================================================\n",
      "Analyzing: /workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_medium.jsonl\n",
      "================================================================================\n",
      "Total examples: 9485\n",
      "\n",
      "MEDIUM:\n",
      "  Count: 9485\n",
      "  Mean: 501.84 tokens\n",
      "  Std: 236.30 tokens\n",
      "  Min: 104 tokens\n",
      "  Max: 1356 tokens\n",
      "  Median: 455 tokens\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "File                                     Mode       Count    Mean       Std       \n",
      "--------------------------------------------------------------------------------\n",
      "combined_sft_train_high.jsonl            high       5641     1514.3     453.0     \n",
      "combined_sft_train_low.jsonl             low        10388    104.7      53.9      \n",
      "combined_sft_train_medium.jsonl          medium     9485     501.8      236.3     \n",
      "\n",
      "================================================================================\n",
      "FOR REWARD MODEL CODE:\n",
      "================================================================================\n",
      "\n",
      "# combined_sft_train_high.jsonl\n",
      "self.mode_params = {\n",
      "    'high': {'mean': 1514, 'std': 452},\n",
      "}\n",
      "\n",
      "# combined_sft_train_low.jsonl\n",
      "self.mode_params = {\n",
      "    'low': {'mean': 104, 'std': 53},\n",
      "}\n",
      "\n",
      "# combined_sft_train_medium.jsonl\n",
      "self.mode_params = {\n",
      "    'medium': {'mean': 501, 'std': 236},\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def analyze_thinking_lengths(files):\n",
    "    \"\"\"\n",
    "    Analyze thinking lengths for each file and mode\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for file_path in files:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Analyzing: {file_path}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Read data\n",
    "        data = []\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå File not found: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Total examples: {len(data)}\")\n",
    "        \n",
    "        # Group by mode and extract thinking lengths\n",
    "        mode_lengths = defaultdict(list)\n",
    "        \n",
    "        for item in data:\n",
    "            mode = item.get('mode', 'unknown').lower()\n",
    "            response = item.get('response', '')\n",
    "            \n",
    "            # Extract thinking content\n",
    "            match = re.search(r'<think>(.*?)</think>', response, re.DOTALL)\n",
    "            if match:\n",
    "                thinking = match.group(1).strip()\n",
    "                # Approximate token count (characters / 4)\n",
    "                length = len(thinking) // 4\n",
    "                mode_lengths[mode].append(length)\n",
    "        \n",
    "        # Calculate statistics for each mode\n",
    "        file_results = {}\n",
    "        for mode in ['low', 'medium', 'high']:\n",
    "            if mode in mode_lengths:\n",
    "                lengths = mode_lengths[mode]\n",
    "                mean = np.mean(lengths)\n",
    "                std = np.std(lengths)\n",
    "                \n",
    "                file_results[mode] = {\n",
    "                    'count': len(lengths),\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'min': min(lengths),\n",
    "                    'max': max(lengths),\n",
    "                    'median': np.median(lengths)\n",
    "                }\n",
    "                \n",
    "                print(f\"\\n{mode.upper()}:\")\n",
    "                print(f\"  Count: {len(lengths)}\")\n",
    "                print(f\"  Mean: {mean:.2f} tokens\")\n",
    "                print(f\"  Std: {std:.2f} tokens\")\n",
    "                print(f\"  Min: {min(lengths)} tokens\")\n",
    "                print(f\"  Max: {max(lengths)} tokens\")\n",
    "                print(f\"  Median: {np.median(lengths):.0f} tokens\")\n",
    "        \n",
    "        results[file_path] = file_results\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n{'File':<40} {'Mode':<10} {'Count':<8} {'Mean':<10} {'Std':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for file_path, modes in results.items():\n",
    "        filename = file_path.split('/')[-1]\n",
    "        for mode in ['low', 'medium', 'high']:\n",
    "            if mode in modes:\n",
    "                stats = modes[mode]\n",
    "                print(f\"{filename:<40} {mode:<10} {stats['count']:<8} {stats['mean']:<10.1f} {stats['std']:<10.1f}\")\n",
    "    \n",
    "    # Code output\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FOR REWARD MODEL CODE:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for file_path, modes in results.items():\n",
    "        filename = file_path.split('/')[-1]\n",
    "        print(f\"\\n# {filename}\")\n",
    "        print(\"self.mode_params = {\")\n",
    "        for mode in ['low', 'medium', 'high']:\n",
    "            if mode in modes:\n",
    "                mean = int(modes[mode]['mean'])\n",
    "                std = int(modes[mode]['std'])\n",
    "                print(f\"    '{mode}': {{'mean': {mean}, 'std': {std}}},\")\n",
    "        print(\"}\")\n",
    "\n",
    "# Analyze all three files\n",
    "files = [\n",
    "    '/workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_high.jsonl',\n",
    "    '/workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_low.jsonl',\n",
    "    '/workspace/LLaMA-OSS/LLaMA-Factory/data/combined_sft_train_medium.jsonl'\n",
    "]\n",
    "\n",
    "analyze_thinking_lengths(files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khoina_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
